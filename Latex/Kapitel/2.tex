\chapter{Neuronale Netze in Tensorflow}
Neuronale Netze sind das am häufigsten benutzte Werkzeug in Tensorflow. Im Folgenden werden die Grundlagen für Neuronale Netze vorgestellt, sowie deren Umsetzung in Tensorflow. Diverse Codeauschnitte in diesem und alle nachfolgenden Kapitel sind Implementierungen in der Programmiersprache Python. Diese werden in den Pythoncode eingebunden. Dabei wird mit \cite{cookbook}
\begin{lstlisting}
import tensorflow as tf
\end{lstlisting} Tensorflow in Python importiert. Tensorflow Befehle können dann über das Kürzel \lstinline$tf.$ aufgerufen werden.

\section{Feedforward Netzwerk}
Die häufigste in Tensorflow implementierte Version Neuronaler Netze ist das feedforward network oder ein vorwärtsgerichtetes Netzwerk. Es heißt so, da Informationen innerhalb des Netzes immer weiter nach $"$vorne$"$ wandern, von den Eingabeneuronen über die versteckten Schichten zu den Ausgabeneuronen.\cite{Goodfellow} Es gibt keine Rückkopplungen, wie es zum Beispiel beim Hopfieldnetz der Fall ist.\cite{Ertel2013} Sie werden am h\"aufigsten f\"ur Deep Learning verwendet.\cite{Goodfellow} Ein feedforward Netz besteht aus einer Eingabeschicht, einer Ausgabeschicht und n versteckten Schichten dazwischen.
\begin{figure}[!htp]
	\setlength{\unitlength}{1cm}
	\centering
	\begin{picture}(4,3.5)
	\label{FeedForward}
	
	\put(-0.2,0.5){\textcolor{blue}{$w_{1,1}$}}
	\put(1.35,0.26){\textcolor{blue}{$w_{2,1}$}}
	\put(2.8,0.2){\textcolor{blue}{$w_{n,1}$}}
	\put(4.1,0.6){\textcolor{green}{$w_{n,{m_1}}$}}
	
	\put(0.53,-0.1){$x_1$}
	\put(2.05,-0.1){$x_2$}
	\put(3.54,-0.1){$x_n$}
	\put(4.5,-0.1){\textbf{Inputschicht}}
	
	\put(0.75,0){\circle{0.5}}
	\put(2.25,0){\circle{0.5}}
	\put(3.75,0){\circle{0.5}}
	
	\put(0,1.5){\circle{0.5}}
	\put(1.5,1.5){\circle{0.5}}
	\put(3,1.5){\circle{0.5}}
	\put(4.5,1.5){\circle{0.5}}
	\put(5.25,1.35){\textbf{Versteckte Schicht}}
	
	\put(1.5,3){\circle{0.5}}
	\put(1.3,2.9){$o_1$}
	\put(3,3){\circle{0.5}}
	\put(2.8,2.9){$o_2$}
	\put(4.05,2.85){\textbf{Outputschicht}}
	
	\put(0.75,0.25){\textcolor{blue}{\line(-3,5){0.63}}}
	\put(0.75,0.25){\line(3,5){0.63}}
	\put(0.75,0.25){\line(2,1){2.1}}
	\put(0.75,0.25){\line(3,1){3.5}}
	
	\put(2.25,0.25){\line(-3,5){0.63}}
	\put(2.25,0.25){\line(3,5){0.63}}
	\put(2.25,0.25){\line(2,1){2.1}}
	\put(2.25,0.25){\textcolor{blue}{\line(-5,3){2}}}
	
	\put(3.75,0.25){\line(-3,5){0.63}}
	\put(3.75,0.25){\textcolor{green}{\line(3,5){0.63}}}
	\put(3.75,0.25){\textcolor{blue}{\line(-3,1){3.5}}}
	\put(3.75,0.25){\line(-5,3){2}}
	
	\put(0,1.75){\line(1,1){1.25}}
	\put(0,1.75){\line(2,1){2.77}}
	
	\put(1.5,1.75){\line(1,1){1.25}}
	\put(1.5,1.75){\line(0,1){1}}
	
	\put(3,1.75){\line(-1,1){1.25}}
	\put(3,1.75){\line(0,1){1}}
	
	\put(4.5,1.75){\line(-1,1){1.25}}
	\put(4.5,1.75){\line(-2,1){2.77}}

	\end{picture}
	\caption{feedforward Netz}
\end{figure}
Hierbei ist jedes Neuron mit jedem Neuron der nachfolgenden Schicht durch Gewichte verbunden.\\
Die Abbildung zeigt beispielhaft ein feedforward Netzwerk mit 3 Input-Neuronen in der Eingabeschicht, einer versteckten Schicht mit 4 versteckten Neuronen und einer Ausgabeschicht mit 2 Ausgabe-Neuronen.\cite{Bishop1995}\\
Ein feedforward Netzwerk kann beliebig viele versteckten Schichten enthalten, aber nur eine Eingabe und eine Ausgabeschicht. Ebenso kann die Anzahl der Neuronen in den versteckten Schichten frei gew\"ahlt werden. Eine sinnvolle Anzahl von Neuronen in den versteckten Schichten, genauso wie eine möglichst gute Anzahl der versteckten Schichten für das jeweilige Problem lassen sich nur experimentell bestimmen.\cite{handson} Man sollte darauf achten nicht zu wenige Neuronen zu verwenden da sonst die Lernkapazit\"at möglicherwei\ss e zu eingeschränkt ist. Auch zu viele Neuronen können problematisch sein, da es sehr lang dauern kann jedes der vielen Neuronen zu trainieren und die Effizienz des Netzwerks darunter leidet.\cite{Rashid} \\ Man kann bereits mit einer versteckten Schicht und einer ausreichend gro\ss en Anzahl Neuronen jedes Problem simulieren, tendenziell ist es aber besser die Anzahl der Schichten zu erhöhen anstatt die Anzahl der Neuronen pro Schicht.\cite{handson} 
\section{Der Input Tensor}
Vektoren und Matrizen werden in Tensorflow als Tensors bezeichnet. Der Input eines Neuronalen Netzes ist ein n-dimensionaler Vektor der für jedes Input-Neuron einen Wert enthält. Die Anzahl der Input-Neuronen richtet sich nach dem untersuchten Problem. Das Einführungsbeispiel für Tensorflow das in etwa dem $"$Hello World$"$ f\"ur Programmiersprachen entspricht, behandelt ein Klassifikationsproblem.\cite{handson} In diesem Problem sollen mithilfe der MNIST Datenbank die tausende von handgeschriebenen $28 \times 28$ Bilder der Zahlen von 1-9 enthält, das Neuronale Netz lernen handgeschriebene Ziffern zu unterscheiden. Für jedes dieser Bilder hat man entsprechend eine $28 \times 28$ Matrix mit Grauwerten. Mit dem Befehl \lstinline$reshape(-1,..)$ \cite{handson} lässt es sich in einen eindimensionalen Vektor mit  $28*28=784$ Input Neuronen verwandeln.\\
Input-Tensore werden in Tensorflow mit Platzhaltern angelegt, da während des Lernprozesses der Inputtensor für jedes zu lernende Beispiel aktualisiert wird. Um den Platzhalter anzulegen verwendet man den Befehl\cite{cookbook}
\begin{lstlisting}
input= tf.placeholder("float",[None,Input_Neuronen])
\end{lstlisting}
Mit float wird der Datentyp des inputs für die einzelnen Neuronen gewählt. Die Variable \lstinline$Input_Neuronen$ gibt die Anzahl der Input Neuronen an. Das None steht f\"ur die Anzahl der Trainingsdaten, die später noch dynamisch eingefügt wird. So muss man sich zunächst nicht festlegen wie viele Trainingsdaten man benutzen will.\cite{handson} 

\section{Gewichte}
Man kann alle Gewichte zwischen Inputschicht und der ersten versteckten Schicht als Gewichtsmatrix \begin{equation}
W\textsuperscript{(1)}:=
\begin{pmatrix}
w_{1,1}\textsuperscript{(1)} & w_{1,2}\textsuperscript{(1)} & \cdots & w_{1,m_1}\textsuperscript{(1)} \\
w_{2,1}\textsuperscript{(1)} & w_{2,2}\textsuperscript{(1)}& \cdots & .\\
w_{3,1}\textsuperscript{(1)} & w_{3,2}\textsuperscript{(1)}& \cdots & .\\
\vdots & \vdots & \vdots & \vdots \\
w_{n,1}\textsuperscript{(1)} & w_{n,2}\textsuperscript{(1)} & \cdots & w_{n,m_1}\textsuperscript{(1)}\\
\end{pmatrix} \end{equation}
auffassen.\\\\
Die Zeilen von $W\textsuperscript{(1)}$ entsprechen allen ausgehenden Verbindungen für ein Neuron aus der Input-Schicht. Die Spalten entsprechen den eingehenden Verbindungen für ein Neuron aus der versteckten Schicht. \\\\
Der Tensorflow Befehl um die Gewichte zwischen zwei Schicht zu Initialisieren lautet\cite{handson}
\begin{lstlisting}
init = tf.truncated_normal(n_inputs, n_neurons)
W = tf.Variable(init,name="weights")
\end{lstlisting}
Damit werden die Gewichte mit zufälligen Gewichten belegt und es wird eine Matrix bzw Tensor der Dimension \lstinline$(input_neuronen$$ \times $\lstinline$versteckte_neuronen)$ erzeugt.\\
Um den Output des Neuronalen Netzes zu berechnen führt man den Befehl\\ \lstinline$tf.matmul(input,W)$ eine Matrix Multiplikation zwischen Input-Tensor und Gewichtsmatrix durch.\cite{handson} \\
Auf diese Weise bekommt man einen weiteren Tensor der für jedes versteckte Neuron einen Wert hat. Auf diese Werte wendet man nun eine Aktivierungsfunktion an, das Ergebnis nennt man \textbf{Aktivit\"at}\cite{Ertel2013} der versteckten Schicht. Dieses Verfahren kann man nun für beliebig viele versteckte Schichten wiederholen, dabei nutzt man die Aktivität und die Gewichtsmatrix für die zweite versteckte Schicht um eine Matrix Multiplikation durchzuführen und die Aktivität der nächsten Schicht zu bekommen.
\section{Aktivierungsfunktionen}
Aktivierungsfunktionen werden verwendet um den Wertebereich den die Neuronen annehmen können einzugrenzen. So liegen manche Aktivierungsfunktionen nur zwischen den Werten $-1$ und $1$ oder bilden alle negative Werte auf Null ab. Exemplarisch werden 3 häufig verwendete Aktivierungsfunktionen beschrieben.
Während die relu Funktion mittlerweile als Standardaktivierungsfunktion dient, wurden vorher oft die Sigmoidfunktion und die Tangenshyperbolicusfunktion eingesetzt, da ihre Ableitungen leicht zu berechnen sind, weshalb sie sich gut zur Berechnung des Gradienten der Fehlerfunktion eignen.
\subsection{Rectified linear unit function}  \label{sub:relu}
Eine beliebte Möglichkeit ist die Rectified linear unit function, kurz relu.\\
Für relu gilt in der parametrisierten Form\cite{Goodfellow}
\begin{align*}
\sigma(x)=
\left\{
\begin{array}{l l}
& 0 \quad \text{   falls  } \quad x <= 0  \\ 
& ax \quad \text{   sonst}
\end{array}
\right.
\end{align*}
a ist dabei frei wählbar und kann an das jeweilige Beispiel angepasst werden. Obwohl die Relufunktion eine sehr einfache fast lineare Funktion ist, erweist sie sich als sehr Leistungsfähig. Sie dient als Standardaktivierungsfunktion, die für die meisten feedforward Netzwerke empfohlen wird.\cite{Goodfellow} 
Die Relufunktion ist stetig, aber im Nullpunkt nicht differenzierbar.\cite{cookbook} Während der Linksseitige Grenzwert der Ableitung 0 ist, ist der rechtsseitige Grenzwert 1. In der Praxis spielt das kaum eine Rolle, da während des Rechnens meist Werte verwendet werden die nur sehr Nahe an der Null sind und dabei den links- bzw. rechtsseitigen Wert für die Ableitung liefern.\cite{Goodfellow} In Tensorflow ist die Relu Funktion auf verschiedene Arten implementiert, die oben beschriebene Standard Relu Funktion allerdings nur für den Parameterwert a=1. Sie wird mit \cite{cookbook}
\begin{lstlisting}
tf.nn.relu(features, name=None)
\end{lstlisting} 
eingebunden.
Eine andere in tensorflow verwendete Versionen der relu Funktion ist \cite{cookbook}
\begin{lstlisting}
tf.nn.relu6(features, name=None)
\end{lstlisting}
Für diese gilt:
\begin{align*}
	\sigma(x)=
	\left\{
	\begin{array}{l l}
		& 0 \quad \text{   falls  } \quad x <= 0  \\ 
		& x \quad \text{   falls},\quad 0 < x < 6 \\
		& 6 \quad \text{   sonst}
	\end{array}
	\right.
\end{align*}
Sie kann schneller berechet werden und hat den Vorteil das weder Werte nahe der Null verschwinden, noch die Werte zu gro\ss werden können.\cite{cookbook} 
\subsection{Sigmoidfunktion}
Eine andere Aktivierungsfunktion ist die Sigmoid Funktion. Beliebt wurde die Sigmoidfunktion in den 1980er Jahren, um die davor verwendeten Stufenfunktionen zu ersetzen. Die Sigmoidfunktion hatte den Vorteil das sie der Stufenfunktion ähnelte, dabei aber auf dem ganzen Wertebereich differenzierbar war. Sie wurde bis in die 2000er Jahre häufig verwendet. Sie wird mittlerweile häufig durch der Relufunktion ersetzt. \cite{Goodfellow} \\
Die in Tensorflow verwendete Sigmoidfunktion hat folgende Form:\cite{cookbook}
\begin{equation}
\sigma_c(x)=\frac{1}{1+e^{-x}}
\end{equation}
\begin{figure}[!htp]
	\centering
	\includegraphics[page=140,trim = 1.5cm 14.2cm 6cm 5cm,clip=true,scale=0.7]{images/sigmoid.pdf}
	\caption{Sigmoidfunktion \cite{building}}
\end{figure}\\
Der Wertebereich der Sigmoidfunktion liegt zwischen 0 und 1, was sich sehr gut eignet falls die Ausgabewerte des Netzwerks ebenfalls in diesem Bereich liegen. In Tensorflow ist sie mit dem Befehl \lstinline$tf.sigmoid(x, name=None)$\cite{building}
definiert.
\subsection{Tangenshyperbolicus}
Die Tangenshyperbolicusfunktion ähnelt in seiner Struktur und Verwendung stark der Sigmoidfunktion. Sie ist definiert als \cite{Bishop1995}
\begin{equation}
tanh(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}.
\end{equation}
\begin{figure}[!htp]
	\includegraphics[page=3,trim = 10.3cm 22cm 5cm 4.7cm,clip=true,scale=1.4]{images/BackPropRojas.pdf}
	\centering
	\caption{Graph des Tangenshyperbolicus \cite{Rojas1996}}
\end{figure}\\
Wie in der Abbildung ersichtlich wird, befindet sich der Wertebereich des Tangenshyperbolicus im Intervall von [-1,1]. Es wird mit \lstinline$f.tanh(x, name=None)$\cite{building} aufgerufen. Der Tangenshyberbolicus eignet sich vor allem, wenn man den Wertebereich auf negative Zahlen ausdehnen möchte.\cite{cookbook}
\section{Kostenfunktionen}
Kosten- oder Fehlerfunktionen sind ein Ma\ss dafür wie gut ein \gls{NN} lernt. Es stellt eine berechenbare Formel bereit, die den durch das Netz berechneten Output für ein Trainingsbeispiel mit dem zu lernenden Output vergleicht. Au\ss erdem werden sie für das lernen des \gls{NN} benötigt, da aus den Ableitungen der jeweiligen Kostenfunktion für das zugehörige Gewicht die neuen Gewichte gebildet werden.\cite{Goodfellow}
\subsection{MSE}
Eine m\"ogliche Kostenfunktion ist der Mean Squared Error, kurz MSE.
\begin{equation}
MSE=\frac{1}{N}\sum_{i=1}^{N} (\^{o}_i-o_i)^2.
\end{equation}\cite{Rojas1996}
$\^{o}$ steht für den gewünschten Output und $o$ f\"ur den vom Netz für den zugehörigen Input Vektor generierten Output.\\
Der MSE wird mit  \lstinline$Kosten=tf.losses.mean_squared_error(labels,predictions)$\cite{cookbook} eingebunden und summiert die Quadrate der Abweichungen auf, d.h. je geringer der MSE wird, desto genauer hat das Netz die Trainingsdaten gelernt.
\subsection{cross entropy}
Eine andere Möglichkeit ist die sogenannte Cross Entropy Funktion.\cite{Nielsen}
\begin{equation}
CE= - \frac{1}{N} \sum_{i=1}^{N}\^{o}_i \ln o_i + (1- \^{o}_i) \ln (1-o_i)
\end{equation}
Der Vorteil der cross entropy Funktion besteht daran, dass sie je schneller lernt je grö\ss er der anfängliche Fehler ist. Fängt man also bei sehr ungünstig gewählten zufälligen Gewichten mit dem Lernprozess an, wird cross entropy schneller bessere Ergebnisse liefern als der MSE.\cite{Nielsen} Welche man letztendlich verwendet hängt vom zugrunde liegenden Problem ab.\\
Cross entropy wird in Tensorflow mit dem Befehl 
\begin{lstlisting}
Kosten=tf.nn.softmax_cross_entropy_with_logits()
\end{lstlisting}verwendet.\cite{cookbook}
\section{Lernprozess}
Damit das Netz lernt müssen Stück für Stück die Gewichte angepasst werden. Zu diesem Zweck berechnet man die Ableitung der Kostenfunktion und benutzt sie um die Gewichte abzuändern. Dieses Verfahren wird $"$Backpropagation of Error$"$ mittels $"$Gradient Descent$"$ - dem Gradientabstiegsverfahren genannt.\\
Das Update der Gewichte funktioniert nach folgender Regel:\cite{Rojas1996}
\begin{equation}
w_{i,j}=w_{i,j}-\frac{\partial Kosten }{\partial w_{i,j}}\eta,
\end{equation}
wobei $\eta$ die Lernrate darstellt. Diese ist frei wählbar, üblicherweise liegt sie im Bereich von 0.01 und 0.5.\\
Die optimale Lernrate für das gegebene Problem muss experimentell bestimmt werden, da man dazu im Vorfeld keine genauen Vorhersagen machen kann.
Trainiert wird das Netzwerk letztendlich mit dem Befehl \lstinline$tf.train.GradientDescentOptimizer(Lernrate).minimize(Kosten)$\cite{building}
Das Gradientenabstiegsverfahren ist dabei eine der einfachsten Optimierungsalgorithmen für das Lernen. Er gehört zur Gruppe der sogenannten Optimierungsalgorithmen erster Ordnung.\cite{Goodfellow} Darauf aufbauend gibt es eine Reihe von Erweiterungen wie zum Beispiel den $"$Stochastic Gradient Descent$"$.\cite{Goodfellow}